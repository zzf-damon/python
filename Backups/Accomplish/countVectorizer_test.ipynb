{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(min_df=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This is the second second document.',\n",
    "     'And the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "X = vectorizer.fit_transform(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<function sklearn.feature_extraction.text.VectorizerMixin.build_analyzer.<locals>.<lambda>(doc)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "\n",
    "\n",
    "analyze"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 设我们有N个文档。 CountVectorizer首先统计这N个文档中除stop_words之外所出现过的词，生成一个词汇表（设词汇表为V，其长度为|V|）。再生成一个N*|V|的数组，设为A，则A[i, j]代表词汇表V中第j个词在第i个文档中出现的次数。\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result array:\n",
      " [[1 0 0 0 1 0 0 0 0]\n",
      " [0 1 1 1 0 1 1 1 1]]\n",
      "vocabulary list:\n",
      " ['am', 'can', 'even', 'make', 'student', 'stuff', 'this', 'up', 'you']\n",
      "vocabulary_:\n",
      " {'am': 0, 'student': 4, 'you': 8, 'can': 1, 'even': 2, 'make': 3, 'this': 6, 'stuff': 5, 'up': 7}\n",
      "result array:\n",
      " [[1 1 0 1 0 1 0]\n",
      " [3 0 2 1 1 0 1]]\n",
      "vocabulary list:\n",
      " ['中国', '城市', '学校', '小区', '旅行', '都是', '饮食']\n",
      "vocabulary_:\n",
      " {'中国': 0, '城市': 1, '都是': 5, '小区': 3, '学校': 2, '旅行': 4, '饮食': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "X_test = ['I am a student','You can’t even make this stuff up']\n",
    "# stop_words=None表示不去掉停用词，若改为stop_words='english'则去掉停用词；\n",
    "count_vec=CountVectorizer(stop_words=None)\n",
    "# 训练count_vec中的属性，并返回数组\n",
    "arr = count_vec.fit_transform(X_test).toarray()\n",
    "\n",
    "print('result array:\\n', arr)\n",
    "\n",
    "print('vocabulary list:\\n', count_vec.get_feature_names()) # 列表中的词汇按照英文字母表的顺序排列。\n",
    "\n",
    "print('vocabulary_:\\n', count_vec.vocabulary_)\n",
    "\n",
    "#####################################################\n",
    "########## CountVectorizer同样适用于中文 ###############\n",
    "#####################################################\n",
    "\n",
    "X_test = ['中国 你 是 城市 都是 小区', '中国 中国 学校 你 小区 旅行 饮食 学校 中国']\n",
    "## 默认将所有单个汉字视为停用词；\n",
    "count_vec=CountVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b\")\n",
    "arr = count_vec.fit_transform(X_test).toarray()\n",
    "\n",
    "print('result array:\\n', arr)\n",
    "\n",
    "print('vocabulary list:\\n', count_vec.get_feature_names())\n",
    "\n",
    "print('vocabulary_:\\n', count_vec.vocabulary_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 0, 1, 0, 1, 0],\n       [3, 0, 2, 1, 1, 0, 1]], dtype=int64)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 设我们有N个文档。 TfidfVectorizer首先统计这N个文档中除stop_words之外所出现过的词，生成一个词汇表（设词汇表为V，其长度为|V|）。再生成一个N*|V|的数组，设为W，则W[i, j]代表词汇表V中第j个词在第i个文档中的tf-idf值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################################\n",
    "########## TfidfVectorizer ###############\n",
    "#####################################################\n",
    "\n",
    "X_test = ['中国 你 是 城市 都是 小区', '中国 你 小区 旅行 饮食 学校']\n",
    "\n",
    "# 默认将所有单个汉字视为停用词；\n",
    "tfidf_vec=TfidfVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b\")\n",
    "arr = tfidf_vec.fit_transform(X_test).toarray()\n",
    "\n",
    "print('result array:\\n', arr)\n",
    "\n",
    "print('vocabulary list:\\n', tfidf_vec.get_feature_names())\n",
    "\n",
    "print('vocabulary_:\\n', tfidf_vec.vocabulary_)\n",
    "\n",
    "# idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.\n",
    "print('idf:\\n', tfidf_vec.idf_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 设我们有N个文档。 TfidfVectorizer首先统计这N个文档中除stop_words之外所出现过的词，生成一个词汇表（设词汇表为V，其长度为|V|）。再生成一个N*|V|的数组，设为W，则W[i, j]代表词汇表V中第j个词在第i个文档中对应的值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result array:\n",
      " [[2. 0. 1.]\n",
      " [0. 1. 3.]]\n",
      "X_inverse:\n",
      " [{'bar': 2.0, 'foo': 1.0}, {'baz': 1.0, 'foo': 3.0}]\n",
      "X:\n",
      " [[0. 0. 4.]]\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "########## TfidfVectorizer ###############\n",
    "#####################################################\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "D = [{'foo': 1, 'bar': 2},{'foo': 3, 'baz': 1}]\n",
    "X = v.fit_transform(D)\n",
    "print('result array:\\n', X)\n",
    "\n",
    "X_inverse = v.inverse_transform(X)\n",
    "print('X_inverse:\\n', X_inverse)\n",
    "\n",
    "X = v.transform({'foo':4, 'unseen_feature': 3})\n",
    "print('X:\\n', X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}